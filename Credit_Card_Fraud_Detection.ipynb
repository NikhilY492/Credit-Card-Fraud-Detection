{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vatEeKlVGkNK"
      },
      "outputs": [],
      "source": [
        "# fraud_detection_extended.py\n",
        "# Extended training script: adds DecisionTree, KNN, XGBoost (or GradientBoosting fallback)\n",
        "# and computes/saves metrics + ROC/PR/Confusion Matrix plots.\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Optional libs\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except Exception:\n",
        "    XGBClassifier = None\n",
        "    XGBOOST_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    IMBLEARN_AVAILABLE = True\n",
        "except Exception:\n",
        "    SMOTE = None\n",
        "    IMBLEARN_AVAILABLE = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- CONFIG ----------------\n",
        "INPUT_PATH = \"/content/drive/MyDrive/Datasets/fraud_data.csv\"  # keep same as your notebook\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Datasets/outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.3\n",
        "TOP_N_MERCHANTS = 50   # keep top N merchants; others -> 'OTHER' to limit dummies\n",
        "PROB_THRESHOLD = 0.4   # your logistic threshold was 0.4\n",
        "# ----------------------------------------"
      ],
      "metadata": {
        "id": "MwhGKg7vGoec"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- helper functions ----------------\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = math.sin(dlat/2)**2 + math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    r = 6371.0\n",
        "    return r * c\n",
        "\n",
        "def clean_target(df, target_col='is_fraud'):\n",
        "    # convert to string then extract single leading digit (0/1) if corrupted\n",
        "    df[target_col] = df[target_col].astype(str).str.extract(r'([01])')[0]\n",
        "    df[target_col] = pd.to_numeric(df[target_col], errors='coerce').fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "def top_n_group(series, n=TOP_N_MERCHANTS, other_label='OTHER'):\n",
        "    top = series.value_counts().nlargest(n).index\n",
        "    return series.where(series.isin(top), other_label)\n",
        "\n",
        "def save_confusion_matrix(cm, labels, outpath, title=\"Confusion Matrix\"):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=labels, yticklabels=labels, annot_kws={\"size\":12})\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "_zD4H6cbGpHL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Load & preprocess (based on your original notebook) ----------------\n",
        "print(\"Loading:\", INPUT_PATH)\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "# Fix corrupted target values\n",
        "if 'is_fraud' in df.columns:\n",
        "    df = clean_target(df, 'is_fraud')\n",
        "else:\n",
        "    raise ValueError(\"Expected is_fraud column in dataset.\")\n",
        "\n",
        "# Drop any obvious duplicates and useless cols\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "if 'trans_num' in df.columns:\n",
        "    df = df.drop(columns=['trans_num'])\n",
        "\n",
        "# create age\n",
        "# NOTE: original notebook used \"%d-%m-%Y %H:%M\" for trans_date_trans_time and \"%d-%m-%Y\" for dob\n",
        "# Attempt parse robustly with errors='coerce' then compute age (years)\n",
        "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format=\"%d-%m-%Y %H:%M\", errors='coerce')\n",
        "df['dob'] = pd.to_datetime(df['dob'], format=\"%d-%m-%Y\", errors='coerce')\n",
        "df['age'] = ((df['trans_date_trans_time'] - df['dob']).dt.days // 365).fillna(-1).astype(int)\n",
        "\n",
        "# time features\n",
        "df['time_of_day'] = df['trans_date_trans_time'].dt.strftime('%H:%M')\n",
        "df['hour'] = df['trans_date_trans_time'].dt.hour.fillna(-1).astype(int)\n",
        "df['day_of_week'] = df['trans_date_trans_time'].dt.day_name().fillna('Unknown')\n",
        "\n",
        "# distance feature\n",
        "if {'lat','long','merch_lat','merch_long'}.issubset(set(df.columns)):\n",
        "    df['distance_km'] = df.apply(\n",
        "        lambda r: haversine(r['lat'], r['long'], r['merch_lat'], r['merch_long'])\n",
        "                  if pd.notnull(r['lat']) and pd.notnull(r['merch_lat']) else 0.0,\n",
        "        axis=1\n",
        "    )\n",
        "else:\n",
        "    df['distance_km'] = 0.0\n",
        "\n",
        "# job â†’ grouped professions (use your function mapping)\n",
        "def job_categories(profession):\n",
        "    if pd.isna(profession):\n",
        "        return 'Other'\n",
        "    profession_lower = str(profession).lower()\n",
        "    # collapsed mapping for brevity (keeps same logic as your earlier function)\n",
        "    if any(k in profession_lower for k in ['educ', 'teacher', 'lectur', 'professor', 'research']):\n",
        "        return 'Education'\n",
        "    if any(k in profession_lower for k in ['nurs', 'therap', 'psych', 'health', 'medical', 'clinic', 'pharm']):\n",
        "        return 'Healthcare'\n",
        "    if any(k in profession_lower for k in ['engineer', 'scientist', 'developer', 'geoscientist','technolog']):\n",
        "        return 'STEM'\n",
        "    if any(k in profession_lower for k in ['account', 'tax', 'finance', 'bank', 'manager', 'sales']):\n",
        "        return 'Business'\n",
        "    if any(k in profession_lower for k in ['artist', 'designer', 'media', 'journalist', 'musician']):\n",
        "        return 'Creative'\n",
        "    if any(k in profession_lower for k in ['architect', 'construction', 'surveyor', 'civil']):\n",
        "        return 'Construction'\n",
        "    if any(k in profession_lower for k in ['police','fire','armed','civil service','government']):\n",
        "        return 'PublicSector'\n",
        "    if any(k in profession_lower for k in ['pilot']):\n",
        "        return 'Pilot'\n",
        "    return 'Other'\n",
        "\n",
        "df['professions'] = df['job'].apply(job_categories)\n",
        "\n",
        "# cast some columns\n",
        "for c in ['merchant','category','city','state','day_of_week','professions']:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].astype(str)\n",
        "\n",
        "# Reduce merchant cardinality\n",
        "if 'merchant' in df.columns:\n",
        "    df['merchant'] = top_n_group(df['merchant'], n=TOP_N_MERCHANTS)\n",
        "\n",
        "# choose feature columns similar to your earlier dftree\n",
        "features = []\n",
        "for c in ['merchant','category','amt','city_pop','age','hour','day_of_week','distance_km','professions']:\n",
        "    if c in df.columns:\n",
        "        features.append(c)\n",
        "\n",
        "print(\"Using features:\", features)\n",
        "print(\"Target distribution:\\n\", df['is_fraud'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzQGSE3FGs61",
        "outputId": "646a7a42-3112-4f01-d4ad-df635e684e40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: /content/drive/MyDrive/Datasets/fraud_data.csv\n",
            "Using features: ['merchant', 'category', 'amt', 'city_pop', 'age', 'hour', 'day_of_week', 'distance_km', 'professions']\n",
            "Target distribution:\n",
            " is_fraud\n",
            "0    12601\n",
            "1     1782\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Encode features (one-hot for categorical) ----------------\n",
        "cat_cols = [c for c in features if df[c].dtype == 'object' or df[c].dtype.name == 'category']\n",
        "num_cols = [c for c in features if c not in cat_cols]\n",
        "\n",
        "# One-hot encode categorical columns (safe for all models)\n",
        "X = pd.get_dummies(df[features], columns=cat_cols, drop_first=True)\n",
        "y = df['is_fraud'].astype(int)\n",
        "\n",
        "print(\"After get_dummies, feature count:\", X.shape[1])\n",
        "\n",
        "# train/test split (stratify)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
        "print(\"Train/test shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# Optionally resample using SMOTE if available\n",
        "if IMBLEARN_AVAILABLE:\n",
        "    print(\"SMOTE available: performing oversampling on training set.\")\n",
        "    sm = SMOTE(random_state=RANDOM_STATE)\n",
        "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "else:\n",
        "    print(\"SMOTE not available: using original training set (or you can enable undersampling).\")\n",
        "    X_train_res, y_train_res = X_train.copy(), y_train.copy()\n",
        "\n",
        "# For LR and KNN we scale numeric columns. We'll scale the entire matrix to be consistent.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdwUq9oCG3_N",
        "outputId": "bc5b0c6e-0f93-4b67-ff7a-5a23bdce7bfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After get_dummies, feature count: 82\n",
            "Train/test shapes: (10068, 82) (4315, 82)\n",
            "SMOTE available: performing oversampling on training set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Define models ----------------\n",
        "models = {}\n",
        "models['LogisticRegression'] = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
        "models['RandomForest'] = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE)\n",
        "models['DecisionTree'] = DecisionTreeClassifier(class_weight='balanced', random_state=RANDOM_STATE)\n",
        "models['KNN'] = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "if XGBOOST_AVAILABLE:\n",
        "    models['XGBoost'] = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "else:\n",
        "    models['GradientBoosting'] = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "print(\"Models to train:\", list(models.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDqZ-SbPG7Q_",
        "outputId": "7183264a-1404-4260-96ed-afba0abdd6b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models to train: ['LogisticRegression', 'RandomForest', 'DecisionTree', 'KNN', 'XGBoost']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Train, predict, evaluate ----------------\n",
        "metrics = []\n",
        "roc_curves = {}\n",
        "pr_curves = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(\"\\n--- Training:\", name)\n",
        "    # For tree-based models we can fit on unscaled (X_train_res), but scaled works for all; use scaled for consistency\n",
        "    try:\n",
        "        model.fit(X_train_scaled, y_train_res)\n",
        "    except Exception as e:\n",
        "        # fallback to unscaled if model fails on sparse dense shape mismatch\n",
        "        print(f\"Fit failed on scaled data for {name}: {e}; trying unscaled features.\")\n",
        "        model.fit(X_train_res, y_train_res)\n",
        "\n",
        "    # predict probabilities/scores\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_score = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    else:\n",
        "        # decision_function or predict\n",
        "        if hasattr(model, \"decision_function\"):\n",
        "            y_score = model.decision_function(X_test_scaled)\n",
        "        else:\n",
        "            y_score = model.predict(X_test_scaled).astype(float)\n",
        "\n",
        "    # predictions with same threshold logic (for LR you used 0.4 earlier, but for consistent comparison use 0.5)\n",
        "    y_pred = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    # metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, y_score)\n",
        "    except Exception:\n",
        "        roc_auc = np.nan\n",
        "    try:\n",
        "        pr_auc = average_precision_score(y_test, y_score)\n",
        "    except Exception:\n",
        "        pr_auc = np.nan\n",
        "\n",
        "    print(f\"{name} metrics -> Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}\")\n",
        "    print(\"Classification report:\\n\", classification_report(y_test, y_pred, digits=4, zero_division=0))\n",
        "\n",
        "    # confusion matrix plot saved\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cm_path = os.path.join(OUTPUT_DIR, f\"confusion_matrix_{name}.png\")\n",
        "    save_confusion_matrix(cm, labels=[\"Not Fraud\",\"Fraud\"], outpath=cm_path, title=f\"{name} Confusion Matrix\")\n",
        "    print(\"Saved confusion matrix to:\", cm_path)\n",
        "\n",
        "    # store metrics\n",
        "    metrics.append({\n",
        "        'model': name,\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'pr_auc': pr_auc\n",
        "    })\n",
        "\n",
        "    # curves\n",
        "    try:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "        roc_curves[name] = (fpr, tpr)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "        pr_curves[name] = (precision, recall)\n",
        "    except Exception:\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4MaSCKG_KC",
        "outputId": "fcb7bc1d-4107-4b18-f66e-c0df782c7171"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training: LogisticRegression\n",
            "LogisticRegression metrics -> Acc: 0.9423, Prec: 0.8206, Rec: 0.6841, F1: 0.7462, ROC-AUC: 0.8980, PR-AUC: 0.7183\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9563    0.9788    0.9674      3780\n",
            "           1     0.8206    0.6841    0.7462       535\n",
            "\n",
            "    accuracy                         0.9423      4315\n",
            "   macro avg     0.8885    0.8315    0.8568      4315\n",
            "weighted avg     0.9395    0.9423    0.9400      4315\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/Datasets/outputs/confusion_matrix_LogisticRegression.png\n",
            "\n",
            "--- Training: RandomForest\n",
            "RandomForest metrics -> Acc: 0.9727, Prec: 0.9033, Rec: 0.8729, F1: 0.8878, ROC-AUC: 0.9882, PR-AUC: 0.9562\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9821    0.9868    0.9844      3780\n",
            "           1     0.9033    0.8729    0.8878       535\n",
            "\n",
            "    accuracy                         0.9727      4315\n",
            "   macro avg     0.9427    0.9298    0.9361      4315\n",
            "weighted avg     0.9723    0.9727    0.9725      4315\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/Datasets/outputs/confusion_matrix_RandomForest.png\n",
            "\n",
            "--- Training: DecisionTree\n",
            "DecisionTree metrics -> Acc: 0.9655, Prec: 0.8305, Rec: 0.9065, F1: 0.8668, ROC-AUC: 0.9402, PR-AUC: 0.7645\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9866    0.9738    0.9802      3780\n",
            "           1     0.8305    0.9065    0.8668       535\n",
            "\n",
            "    accuracy                         0.9655      4315\n",
            "   macro avg     0.9085    0.9402    0.9235      4315\n",
            "weighted avg     0.9672    0.9655    0.9661      4315\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/Datasets/outputs/confusion_matrix_DecisionTree.png\n",
            "\n",
            "--- Training: KNN\n",
            "KNN metrics -> Acc: 0.9020, Prec: 0.6373, Rec: 0.4860, F1: 0.5514, ROC-AUC: 0.8306, PR-AUC: 0.5225\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9296    0.9608    0.9450      3780\n",
            "           1     0.6373    0.4860    0.5514       535\n",
            "\n",
            "    accuracy                         0.9020      4315\n",
            "   macro avg     0.7834    0.7234    0.7482      4315\n",
            "weighted avg     0.8934    0.9020    0.8962      4315\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/Datasets/outputs/confusion_matrix_KNN.png\n",
            "\n",
            "--- Training: XGBoost\n",
            "XGBoost metrics -> Acc: 0.9791, Prec: 0.9068, Rec: 0.9271, F1: 0.9168, ROC-AUC: 0.9930, PR-AUC: 0.9714\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9896    0.9865    0.9881      3780\n",
            "           1     0.9068    0.9271    0.9168       535\n",
            "\n",
            "    accuracy                         0.9791      4315\n",
            "   macro avg     0.9482    0.9568    0.9524      4315\n",
            "weighted avg     0.9794    0.9791    0.9792      4315\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/Datasets/outputs/confusion_matrix_XGBoost.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Save metrics dataframe ----------------\n",
        "metrics_df = pd.DataFrame(metrics).sort_values(by='pr_auc', ascending=False).reset_index(drop=True)\n",
        "metrics_csv = os.path.join(OUTPUT_DIR, \"model_metrics_summary.csv\")\n",
        "metrics_df.to_csv(metrics_csv, index=False)\n",
        "print(\"\\nSaved metrics summary to:\", metrics_csv)\n",
        "print(metrics_df)\n",
        "\n",
        "# ---------------- Plot combined ROC ----------------\n",
        "if roc_curves:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    for name, (fpr, tpr) in roc_curves.items():\n",
        "        auc_val = roc_auc_score(y_test, models[name].predict_proba(X_test_scaled)[:,1]) if hasattr(models[name], 'predict_proba') else np.nan\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{name} (AUC={metrics_df.loc[metrics_df['model']==name,'roc_auc'].values[0]:.3f})\")\n",
        "    plt.plot([0,1],[0,1], color='gray', linestyle='--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curves - All Models\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    roc_png = os.path.join(OUTPUT_DIR, \"roc_curves_all_models.png\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(roc_png)\n",
        "    plt.close()\n",
        "    print(\"Saved ROC curves to:\", roc_png)\n",
        "else:\n",
        "    print(\"No ROC curves to plot.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20599IIdHJQF",
        "outputId": "7d4e02e5-0ed4-4cef-b4fb-39d06e69531e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved metrics summary to: /content/drive/MyDrive/Datasets/outputs/model_metrics_summary.csv\n",
            "                model  accuracy  precision    recall        f1   roc_auc  \\\n",
            "0             XGBoost  0.979143   0.906764  0.927103  0.916821  0.993034   \n",
            "1        RandomForest  0.972654   0.903288  0.872897  0.887833  0.988242   \n",
            "2        DecisionTree  0.965469   0.830479  0.906542  0.866845  0.940176   \n",
            "3  LogisticRegression  0.942294   0.820628  0.684112  0.746177  0.898008   \n",
            "4                 KNN  0.901970   0.637255  0.485981  0.551432  0.830617   \n",
            "\n",
            "     pr_auc  \n",
            "0  0.971401  \n",
            "1  0.956177  \n",
            "2  0.764452  \n",
            "3  0.718280  \n",
            "4  0.522504  \n",
            "Saved ROC curves to: /content/drive/MyDrive/Datasets/outputs/roc_curves_all_models.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Plot combined Precision-Recall ----------------\n",
        "if pr_curves:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    for name, (precision, recall) in pr_curves.items():\n",
        "        # compute approx pr auc for label\n",
        "        try:\n",
        "            auc_pr = metrics_df.loc[metrics_df['model']==name,'pr_auc'].values[0]\n",
        "        except Exception:\n",
        "            auc_pr = np.nan\n",
        "        plt.plot(recall, precision, lw=2, label=f\"{name} (PR-AUC={auc_pr:.3f})\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precision-Recall Curves - All Models\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(True)\n",
        "    pr_png = os.path.join(OUTPUT_DIR, \"pr_curves_all_models.png\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(pr_png)\n",
        "    plt.close()\n",
        "    print(\"Saved PR curves to:\", pr_png)\n",
        "else:\n",
        "    print(\"No PR curves to plot.\")\n",
        "\n",
        "print(\"\\nAll done. Outputs saved to folder:\", OUTPUT_DIR)\n",
        "print(\"Model metrics:\\n\", metrics_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFxm-JMzHNTB",
        "outputId": "5cbdbe43-0672-4578-f84f-5d76f258f6b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PR curves to: /content/drive/MyDrive/Datasets/outputs/pr_curves_all_models.png\n",
            "\n",
            "All done. Outputs saved to folder: /content/drive/MyDrive/Datasets/outputs\n",
            "Model metrics:\n",
            "              model  accuracy  precision   recall       f1  roc_auc   pr_auc\n",
            "           XGBoost  0.979143   0.906764 0.927103 0.916821 0.993034 0.971401\n",
            "      RandomForest  0.972654   0.903288 0.872897 0.887833 0.988242 0.956177\n",
            "      DecisionTree  0.965469   0.830479 0.906542 0.866845 0.940176 0.764452\n",
            "LogisticRegression  0.942294   0.820628 0.684112 0.746177 0.898008 0.718280\n",
            "               KNN  0.901970   0.637255 0.485981 0.551432 0.830617 0.522504\n"
          ]
        }
      ]
    }
  ]
}